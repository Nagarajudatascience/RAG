ğŸ“ Directory Structure (Recommended)
pgsql
Copy
Edit
mentor_recommendation/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ profile_retrieval_agent.py
â”‚   â””â”€â”€ generation_agent.py
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ database.py
â”‚   â””â”€â”€ models.py
â”œâ”€â”€ knowledge_graph/
â”‚   â””â”€â”€ graph_handler.py
â”œâ”€â”€ langchain_module/
â”‚   â”œâ”€â”€ vectorstore.py
â”‚   â””â”€â”€ rag_chain.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ schemas.py
â””â”€â”€ requirements.txt
ğŸ§  agents/orchestrator.py
python
Copy
Edit
from agents.profile_retrieval_agent import get_user_profile
from agents.generation_agent import generate_mentor_response

def orchestrate_recommendation(user_query: str):
    profile = get_user_profile(user_query)
    response = generate_mentor_response(user_query, profile)
    return response
ğŸ‘¤ agents/profile_retrieval_agent.py
python
Copy
Edit
from knowledge_graph.graph_handler import get_profile_from_graph

def get_user_profile(user_query: str):
    # extract keywords or user ID from query
    return get_profile_from_graph(user_query)
ğŸ¤– agents/generation_agent.py
python
Copy
Edit
from langchain_module.rag_chain import run_rag_pipeline

def generate_mentor_response(query: str, profile: dict):
    context = " ".join(profile.get("skills", []))  # enrich query
    return run_rag_pipeline(f"{query} | {context}")
ğŸ—ƒï¸ knowledge_graph/graph_handler.py
python
Copy
Edit
from db.database import SessionLocal
from db.models import Mentor

def get_profile_from_graph(user_query: str):
    db = SessionLocal()
    mentor = db.query(Mentor).filter(Mentor.skills.ilike(f"%{user_query}%")).first()
    return {"name": mentor.name, "skills": mentor.skills.split(",")}
ğŸ§¬ langchain_module/rag_chain.py
python
Copy
Edit
from langchain.chains import RetrievalQA
from langchain.vectorstores import Pinecone
from langchain.embeddings import OpenAIEmbeddings
from langchain.llms import OpenAI

import pinecone

pinecone.init(api_key="your-key", environment="your-env")
index = pinecone.Index("mentor-index")
vectorstore = Pinecone(index, OpenAIEmbeddings(), "text")

rag_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vectorstore.as_retriever()
)

def run_rag_pipeline(query: str):
    return rag_chain.run(query)
ğŸš€ api/main.py
python
Copy
Edit
from fastapi import FastAPI
from pydantic import BaseModel
from agents.orchestrator import orchestrate_recommendation

app = FastAPI()

class Query(BaseModel):
    query: str

@app.post("/recommend")
def recommend_mentor(query: Query):
    response = orchestrate_recommendation(query.query)
    return {"recommendation": response}
ğŸ§¾ db/models.py
python
Copy
Edit
from sqlalchemy import Column, Integer, String
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class Mentor(Base):
    __tablename__ = "mentors"
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String)
    skills = Column(String)
ğŸ§¬ db/database.py
python
Copy
Edit
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

SQLALCHEMY_DATABASE_URL = "postgresql://user:password@localhost/mentor_db"
engine = create_engine(SQLALCHEMY_DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
ğŸ“¦ requirements.txt
nginx
Copy
Edit
fastapi
uvicorn
sqlalchemy
psycopg2
langchain
openai
pinecone-client
pydantic
